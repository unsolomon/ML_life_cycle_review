#  5~7 기초 신경망 이론 핵심

- 순전파/역전파(Backprop), Chain Rule, 계산 그래프로 gradient 흐름 이해 연습 필요
- sigmoid/tanh/relu/leaky relu/elu 등 활성화 함수 장단점, 학습률(learning rate) 조절의 중요성 숙지
- 실무에선 은닉층은 ReLU, 마지막층만 문제에 맞게 activation
- 데이터 전처리(normalization, standardization, augmentation) 직접 실습 추천

## TODO
- Backprop 및 Chain Rule 계산 그래프 직접 연습
- 로지스틱 회귀 역전파 미분 단계별 손으로 다시 풀어보기
- 여러 전처리/정규화 방식 실습

