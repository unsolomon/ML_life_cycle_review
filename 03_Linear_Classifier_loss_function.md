## **Liner Classifier의 작동 방식**

1. **입력 데이터(Input Image)**:
    - 이미지가 입력되면, 각 픽셀 값(예: 56, 231, 24 등)이 **특성(feature)**으로 사용됩니다.
2. **가중치(W)**:
    - 각 클래스(예: 고양이, 강아지, 호랑이 등)에 대해 특정 가중치(w)가 존재합니다.
    - 가중치는 학습 과정에서 결정되며, 각 특성(픽셀 값)의 중요도를 나타냅니다.
3. **편향(b)**:
    - 편향(b)은 모델이 선형 경계를 조정하는 데 사용됩니다.
    - 이는 데이터가 선형적으로 완벽히 구분되지 않을 때 경계를 이동시키는 역할을 합니다.
4. **점수 계산**:
    - 입력 데이터와 가중치의 곱에 편향을 더해 점수를 계산합니다.
    - 수식: f(x)=wx+b*f*(*x*)=*wx*+*b*
        - x: 입력 데이터(특성)
        - w: 가중치
        - b: 편향
    - 이 점수는 각 클래스(고양이, 강아지, 호랑이 등)에 대해 계산됩니다.
5. **결과 해석**:
    - 계산된 점수(Score)는 해당 이미지가 특정 클래스에 속할 가능성을 나타냅니다.
    - 예를 들어, 고양이 클래스의 점수가 가장 높다면, 모델은 해당 이미지를 고양이로 분류합니다.

## **이미지와 관련된 예제 설명**

- 입력 이미지의 픽셀 값이 특성으로 들어갑니다.
- 각 클래스(고양이, 강아지 등)에 대해 가중치($w$)와 편향($b$)이 적용되어 점수가 계산됩니다.
- 예를 들어:
    - 고양이 클래스: f(x) = w_{\text{cat}}x + b_{\text{cat}}
    - 강아지 클래스: f(x) = w_{\text{dog}}x + b_{\text{dog}}
    - 호랑이 클래스: f(x) = w_{\text{tiger}}x + b_{\text{tiger}}
- 계산된 점수 중 가장 높은 값을 가진 클래스가 최종 예측 결과로 선택됩니다.

## **추가적인 해석**

## **문제점:**

- 점수가 너무 큰 값(예: 437.9)으로 나오면 해석하기 어렵습니다.
- 이를 해결하기 위해 **확률로 변환**하는 방법을 사용합니다(예: 소프트맥스 함수).

## **소프트맥스 함수:**

- 점수를 확률로 변환하여 각 클래스에 속할 확률을 제공합니다.
- 예를 들어:
    - 고양이: 70%
    - 강아지: 20%
    - 호랑이: 10%

1. **y (실제 값)**:
2. **y' (모델의 예측값)**:
    - 양수: 모델이 긍정적인 클래스로 예측
    - 음수: 모델이 부정적인 클래스로 예측

y'는 모델의 예측을 나타내며, 그 크기는 모델의 확신도를 나타냅니다. 예를 들어:

- y' = 2.5: 모델이 강하게 긍정 클래스로 예측
- y' = 0.1: 모델이 약하게 긍정 클래스로 예측
- y' = -1.7: 모델이 중간 정도로 부정 클래스로 예측

따라서, y와 y'의 곱이 양수일 때 모델의 예측이 올바르다는 것을 의미합니다. 

이는 모델이 실제 데이터의 참/거짓을 정확히 예측하고 있다는 뜻입니다.

미분 불가한 부분을 해결하는게 : 로그 손실

상황에 맞는 loss 사용하기 

최적화 손실값 

gradient descent 그래프에서 조금씩 손실값이 0이 다가가도록 최적화 값을 찾아감

다양한 문제 존재

1. 표면이 볼록하지 않을 수 있음
2. 비용 함수가 미분 가능한 경우에만 작동한다
3. 국부 최소값으로 수렴하는 속도가 상당히 느릴 수 있음(산에서 내려갈때 모든 방향에 대해 확인하고 내려가야해서 힘듬)

해결 방안 : stochastic gradient desecent  무작위로 샘플링된 하위 집합에 대해서만 수행

가장 극단적인 경우 모든 샘플에 대해 파라미터 업데이트

가장 일반적인 경우 크기의 미니 배치로 수행하는 것- 최적의 크기는 문제, 데이터 및 하드웨어 메모리에 따라 다름

미니 배치가 작을 때, 두배로 늘리면 기울기 추정이 휠씬 안정적, 크기가 커지면 이득은 줄어들고 비용한 두배로 증가 수익감소- diminishing returns